{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find the following data points:\n",
    "- Outlines titles for each topic\n",
    "    - train (✅)\n",
    "    - test (✅)\n",
    "- Wikipedia articles (paragraphs) (✅) - 29794697 documents\n",
    "- Relevant matching between outlines on TQA and wikipedia article\n",
    "    - train - `/ssd2/arthur/TRECCAR/benchmarkY1/benchmarkY1-train/train.pages.cbor-hierarchical.qrels` (✅)\n",
    "\n",
    "`trec-car-tools` documentation: https://trec-car-tools.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:41:11.540328Z",
     "start_time": "2019-12-02T09:41:11.535224Z"
    }
   },
   "outputs": [],
   "source": [
    "data_home = \"/ssd2/arthur/TRECCAR/\"\n",
    "import os\n",
    "from trec_car import read_data\n",
    "from tqdm.auto import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T19:12:33.519117Z",
     "start_time": "2019-12-07T19:12:33.512362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd2/arthur/searchx-scaffolding/notebooks'"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-07T19:16:24.443786Z",
     "start_time": "2019-12-07T19:14:56.672232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a7c5a890ff434ea50e0bc730a0745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "088fb1a4ab057f4fcf7d487006499060c7fe5773\t   \n",
      "\n",
      "099600a10a944114aac406d136b625fb416dd779\t  \n",
      "\n",
      "39f3a46a4ef6a0f8623a440ca323f668eb46c345\t                      \n",
      "\n",
      "4526d62236cee7be109803d49b6cd2aeadeab6d2\t          \n",
      "\n",
      "71853c6197a6a7f222db0f1978c7cb232b87c5ee\t  \n",
      "\n",
      "a47779c6198b85a1a2595c7c9aaab26199ea8084\t               \n",
      "\n",
      "b858cb282617fb0956d960215c8e84d1ccf909c6\t \n",
      "\n",
      "da39a3ee5e6b4b0d3255bfef95601890afd80709\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paragraphs_path = os.path.join(data_home, \"paragraphCorpus/dedup.articles-paragraphs.cbor\")\n",
    "doc_format = \"<DOC>\\n<DOCNO>{}</DOCNO>\\n<TEXT>{}</TEXT>\\n</DOC>\\n\"\n",
    "corpus_path = os.path.join(data_home, \"data\")\n",
    "if not os.path.isdir(corpus_path):\n",
    "    os.mkdir(corpus_path)\n",
    "corpus_path = \"../../TRECCAR/data/wikipedia_paragaphs.trec\"\n",
    "all_docs = dict()\n",
    "with open(corpus_path, 'w', encoding=\"utf-8\") as outf:\n",
    "    for l in tqdm(open(\"../../TRECCAR/data/docs/docs.tsv\")):\n",
    "        try:\n",
    "            paragraph_id, text = l.strip().split(\"\\t\")\n",
    "        except:\n",
    "            print(l)\n",
    "            continue\n",
    "        outf.write(doc_format.format(paragraph_id, text))\n",
    "#         all_docs[paragraph_id] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T15:55:21.524774Z",
     "start_time": "2019-12-02T15:55:21.518407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('enwiki:Breakdancing/World%20championships',\n",
       " 'World championships',\n",
       " ['Breakdancing', 'World championships'])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_topics[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:54:58.801411Z",
     "start_time": "2019-12-02T09:54:58.789474Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_page(headings, depth=1):\n",
    "    for i in headings:\n",
    "        print(\"\\t\"*depth, i[0].heading)X\n",
    "        print_page(i[1], depth=depth+1)\n",
    "\n",
    "def unrol_headings(headings, parents, hierarchy=[]):x\n",
    "    all_headings = []\n",
    "    for i in headings:\n",
    "        cannonical_name = parents+\"/\"+i[0].headingId\n",
    "        all_headings.append((cannonical_name, i[0].heading, hierarchy + [i[0].heading]))\n",
    "        all_headings += (unrol_headings(i[1], cannonical_name, hierarchy + [i[0].heading]))\n",
    "    return all_headings\n",
    "a = unrol_headings(page.deep_headings_list(), page.page_id, hierarchy = [page.page_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T16:12:11.236224Z",
     "start_time": "2019-12-02T16:12:11.231970Z"
    }
   },
   "outputs": [],
   "source": [
    "all_topics = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T16:12:38.935490Z",
     "start_time": "2019-12-02T16:12:38.929906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T13:52:35.666231Z",
     "start_time": "2019-12-04T13:52:35.387691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c9ad1a2e6b481191fa8011e270d3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c279dbe90a4697b4505703290939f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topics_test = \"../../TRECCAR/benchmarkY2.public/benchmarkY2.cbor-outlines.cbor\"\n",
    "multi_level = 0\n",
    "test_topics = []\n",
    "train_topics = []\n",
    "test_topics_path = \"../../TRECCAR/data/topics/test-topics_flat.txt\"\n",
    "with open(test_topics_path, 'w', encoding='utf-8') as outf:\n",
    "    for page in tqdm(read_data.iter_annotations(open(topics_test, 'rb'))):\n",
    "        all_topics+=1\n",
    "        level_1_headings = len(page.nested_headings())\n",
    "        l = page.flat_headings_list()\n",
    "        flat_list = unrol_headings(page.deep_headings_list(), page.page_id, hierarchy = [page.page_name])\n",
    "        if len(flat_list) != level_1_headings:\n",
    "            multi_level +=1\n",
    "            test_topics+=flat_list\n",
    "            for _id, name, hierarchy in flat_list:\n",
    "                outf.write(\"{};{};{}\\n\".format(_id, name, \"->\".join(hierarchy)))\n",
    "            \n",
    "\n",
    "train_path = \"../../TRECCAR/benchmarkY1/benchmarkY1-train/train.pages.cbor-outlines.cbor\"\n",
    "train_topics_path = \"../../TRECCAR/data/topics/train-topics_flat.txt\"\n",
    "with open(train_topics_path, 'w', encoding='utf-8') as outf:\n",
    "    for page in tqdm(read_data.iter_annotations(open(train_path, 'rb'))):\n",
    "        level_1_headings = len(page.nested_headings())\n",
    "        l = page.flat_headings_list()\n",
    "        flat_list = unrol_headings(page.deep_headings_list(), page.page_id, hierarchy = [page.page_name])\n",
    "        train_topics+=flat_list\n",
    "        for _id, name, hierarchy in flat_list:\n",
    "            outf.write(\"{};{};{}\\n\".format(_id, name, \" \".join(hierarchy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:55:08.336859Z",
     "start_time": "2019-12-02T09:55:07.805875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create BERT training file\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:55:27.032092Z",
     "start_time": "2019-12-02T09:55:26.954588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8724d689af413ca0aed6feb8c8614b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load relevants\n",
    "from collections import defaultdict\n",
    "relevants = defaultdict(lambda: set())\n",
    "# all_docs = \n",
    "for line in tqdm(open('/ssd2/arthur/TRECCAR/benchmarkY1/benchmarkY1-train/train.pages.cbor-hierarchical.qrels')):\n",
    "    topic, _, doc, label = line.strip().split()\n",
    "    if label == \"1\":\n",
    "        relevants[topic].add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T16:02:46.588213Z",
     "start_time": "2019-12-02T16:02:46.581845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29794697"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T09:56:35.261845Z",
     "start_time": "2019-12-02T09:56:35.252744Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'sac',\n",
       " '##cha',\n",
       " '##ride',\n",
       " '##s',\n",
       " 'are',\n",
       " 'generally',\n",
       " 'built',\n",
       " 'of',\n",
       " 'simple',\n",
       " 'car',\n",
       " '##bo',\n",
       " '##hy',\n",
       " '##dra',\n",
       " '##tes',\n",
       " 'called',\n",
       " 'mono',\n",
       " '##sa',\n",
       " '##cc',\n",
       " '##hari',\n",
       " '##des',\n",
       " 'with',\n",
       " 'general',\n",
       " 'formula',\n",
       " '(',\n",
       " 'cho',\n",
       " ')',\n",
       " 'where',\n",
       " 'n',\n",
       " 'is',\n",
       " 'three',\n",
       " 'or',\n",
       " 'more',\n",
       " '.',\n",
       " 'a',\n",
       " 'typical',\n",
       " 'mono',\n",
       " '##sa',\n",
       " '##cc',\n",
       " '##hari',\n",
       " '##de',\n",
       " 'has',\n",
       " 'the',\n",
       " 'structure',\n",
       " 'h',\n",
       " '–',\n",
       " '(',\n",
       " 'cho',\n",
       " '##h',\n",
       " ')',\n",
       " '(',\n",
       " 'c',\n",
       " '=',\n",
       " 'o',\n",
       " ')',\n",
       " '–',\n",
       " '(',\n",
       " 'cho',\n",
       " '##h',\n",
       " ')',\n",
       " '–',\n",
       " 'h',\n",
       " ',',\n",
       " 'that',\n",
       " 'is',\n",
       " ',',\n",
       " 'an',\n",
       " 'al',\n",
       " '##deh',\n",
       " '##yde',\n",
       " 'or',\n",
       " 'ke',\n",
       " '##tone',\n",
       " 'with',\n",
       " 'many',\n",
       " 'hydro',\n",
       " '##xy',\n",
       " '##l',\n",
       " 'groups',\n",
       " 'added',\n",
       " ',',\n",
       " 'usually',\n",
       " 'one',\n",
       " 'on',\n",
       " 'each',\n",
       " 'carbon',\n",
       " 'atom',\n",
       " 'that',\n",
       " 'is',\n",
       " 'not',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'al',\n",
       " '##deh',\n",
       " '##yde',\n",
       " 'or',\n",
       " 'ke',\n",
       " '##tone',\n",
       " 'functional',\n",
       " 'group',\n",
       " '.',\n",
       " 'examples',\n",
       " 'of',\n",
       " 'mono',\n",
       " '##sa',\n",
       " '##cc',\n",
       " '##hari',\n",
       " '##des',\n",
       " 'are',\n",
       " 'glucose',\n",
       " ',',\n",
       " 'fr',\n",
       " '##uc',\n",
       " '##tose',\n",
       " ',',\n",
       " 'and',\n",
       " 'g',\n",
       " '##ly',\n",
       " '##cera',\n",
       " '##lde',\n",
       " '##hy',\n",
       " '##des',\n",
       " '.',\n",
       " 'however',\n",
       " ',',\n",
       " 'some',\n",
       " 'biological',\n",
       " 'substances',\n",
       " 'commonly',\n",
       " 'called',\n",
       " '\"',\n",
       " 'mono',\n",
       " '##sa',\n",
       " '##cc',\n",
       " '##hari',\n",
       " '##des',\n",
       " '\"',\n",
       " 'do',\n",
       " 'not',\n",
       " 'conform',\n",
       " 'to',\n",
       " 'this',\n",
       " 'formula',\n",
       " '(',\n",
       " 'e',\n",
       " '.',\n",
       " 'g',\n",
       " '.',\n",
       " 'ur',\n",
       " '##onic',\n",
       " 'acids',\n",
       " 'and',\n",
       " 'de',\n",
       " '##ox',\n",
       " '##y',\n",
       " '-',\n",
       " 'sugar',\n",
       " '##s',\n",
       " 'such',\n",
       " 'as',\n",
       " 'fu',\n",
       " '##cos',\n",
       " '##e',\n",
       " ')',\n",
       " 'and',\n",
       " 'there',\n",
       " 'are',\n",
       " 'many',\n",
       " 'chemicals',\n",
       " 'that',\n",
       " 'do',\n",
       " 'conform',\n",
       " 'to',\n",
       " 'this',\n",
       " 'formula',\n",
       " 'but',\n",
       " 'are',\n",
       " 'not',\n",
       " 'considered',\n",
       " 'to',\n",
       " 'be',\n",
       " 'mono',\n",
       " '##sa',\n",
       " '##cc',\n",
       " '##hari',\n",
       " '##des',\n",
       " '(',\n",
       " 'e',\n",
       " '.',\n",
       " 'g',\n",
       " '.',\n",
       " 'formal',\n",
       " '##deh',\n",
       " '##yde',\n",
       " 'cho',\n",
       " 'and',\n",
       " 'in',\n",
       " '##osi',\n",
       " '##to',\n",
       " '##l',\n",
       " '(',\n",
       " 'cho',\n",
       " ')',\n",
       " ')',\n",
       " '.',\n",
       " '<',\n",
       " 'ref',\n",
       " '>']"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T10:56:46.556548Z",
     "start_time": "2019-12-02T10:56:46.549276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d78c3dd9dcf0ed5cfcdc57eaa2254575262a8133',\n",
       " 'fb41aa4399d73ffff7801495138d99eec9c875eb',\n",
       " 'aeb998daa2e5d67a44b389f734f8f0d962f4ae6f',\n",
       " '4436c38db91e7d575ea50af339bad786ce2bb649',\n",
       " '82692f376cd75de052be2a4704b1f07c4171feed',\n",
       " 'd8a630d4495981ee1f85b59cf38a63650f529f14',\n",
       " '3412cf476621c66f865825db871ded37d68b0cef',\n",
       " '84a3b37ef7e871089f8f1c35905f3c8b38cb532b',\n",
       " 'dbf5a71bc54ecafb21bc30051edab6a25b7da680',\n",
       " 'd162a2a933e326199598856d23800ccc2027cba4']"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_docs_ids, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T10:58:50.991355Z",
     "start_time": "2019-12-02T10:57:56.173985Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6cb5ce46f247f383c2ff562496059b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1977), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def truncate_seq_pair(tokens_a, tokens_b, max_length=509):\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) < len(tokens_b):\n",
    "            tokens_b.pop()\n",
    "        else:\n",
    "            tokens_a.pop()\n",
    "\n",
    "with open(\"../../TRECCAR/data/samples/triples_tokenized.bert\", 'w', encoding='utf-8') as outf:\n",
    "    for counter, (canonical_id, topic, hierarchy) in tqdm(enumerate(train_topics), total = len(train_topics)):\n",
    "        query = \" \".join(hierarchy)\n",
    "        tokenized_query = tokenizer.tokenize(query)\n",
    "        relevant_docs = relevants[canonical_id]\n",
    "        for doc in relevants[canonical_id]:\n",
    "            triple_id = \"{}-{}\".format(canonical_id, doc)\n",
    "            doc_text = all_docs[doc]\n",
    "            tokenized_doc = tokenizer.tokenize(doc_text)\n",
    "            truncate_seq_pair(tokenized_query, tokenized_doc)\n",
    "            assert len(final_version) <= 512 \n",
    "            final_version = ['[CLS]']+tokenized_query+['[SEP]']+tokenized_doc+['[SEP]']\n",
    "            outf.write(\"{}\\t{}\\t1\\n\".format(triple_id, str(final_version)))\n",
    "            #negative sampling\n",
    "            neg_docs = random.sample(all_docs_ids, 10)\n",
    "            for neg_doc in neg_docs:\n",
    "                neg_doc = random.choice(all_docs_ids)\n",
    "                doc_text = all_docs[neg_doc]\n",
    "                tokenized_doc = tokenizer.tokenize(doc_text)\n",
    "                truncate_seq_pair(tokenized_query, tokenized_doc)\n",
    "                final_version = ['[CLS]']+tokenized_query+['[SEP]']+tokenized_doc+['[SEP]']\n",
    "                assert len(final_version) <= 512 \n",
    "                outf.write(\"{}\\t{}\\t0\\n\".format(triple_id, str(final_version)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:13:27.984194Z",
     "start_time": "2019-12-04T14:13:27.980010Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T14:19:24.937190Z",
     "start_time": "2019-12-04T14:19:24.909074Z"
    }
   },
   "outputs": [],
   "source": [
    "data = yaml.load(open(\"../src/config-defaults.yaml\"), Loader=yaml.FullLoader)\n",
    "data = {k:v['value'] for (k,v) in data.items()}\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "data = dotdict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../TRECCAR/data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
