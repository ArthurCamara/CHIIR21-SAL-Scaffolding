{
    "graph_0": {
        "_type": "graph",
        "format": "torch",
        "nodes": [
            {
                "name": "module",
                "id": 140000506367616,
                "class_name": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)",
                "parameters": [
                    [
                        "distilbert.embeddings.word_embeddings.weight",
                        [
                            30522,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.position_embeddings.weight",
                        [
                            512,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "pre_classifier.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "pre_classifier.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "classifier.weight",
                        [
                            2,
                            768
                        ]
                    ],
                    [
                        "classifier.bias",
                        [
                            2
                        ]
                    ]
                ],
                "output_shape": [
                    [],
                    [
                        16,
                        2
                    ]
                ],
                "num_parameters": [
                    23440896,
                    393216,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    1536,
                    2
                ]
            },
            {
                "name": "module",
                "id": 140000506367392,
                "class_name": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)",
                "parameters": [
                    [
                        "distilbert.embeddings.word_embeddings.weight",
                        [
                            30522,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.position_embeddings.weight",
                        [
                            512,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "pre_classifier.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "pre_classifier.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "classifier.weight",
                        [
                            2,
                            768
                        ]
                    ],
                    [
                        "classifier.bias",
                        [
                            2
                        ]
                    ]
                ],
                "output_shape": [
                    [],
                    [
                        16,
                        2
                    ]
                ],
                "num_parameters": [
                    23440896,
                    393216,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    1536,
                    2
                ]
            },
            {
                "name": "module",
                "id": 140000285721432,
                "class_name": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)",
                "parameters": [
                    [
                        "distilbert.embeddings.word_embeddings.weight",
                        [
                            30522,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.position_embeddings.weight",
                        [
                            512,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "pre_classifier.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "pre_classifier.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "classifier.weight",
                        [
                            2,
                            768
                        ]
                    ],
                    [
                        "classifier.bias",
                        [
                            2
                        ]
                    ]
                ],
                "output_shape": [
                    [],
                    [
                        16,
                        2
                    ]
                ],
                "num_parameters": [
                    23440896,
                    393216,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    1536,
                    2
                ]
            },
            {
                "name": "module",
                "id": 140000285781744,
                "class_name": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)",
                "parameters": [
                    [
                        "distilbert.embeddings.word_embeddings.weight",
                        [
                            30522,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.position_embeddings.weight",
                        [
                            512,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "pre_classifier.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "pre_classifier.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "classifier.weight",
                        [
                            2,
                            768
                        ]
                    ],
                    [
                        "classifier.bias",
                        [
                            2
                        ]
                    ]
                ],
                "output_shape": [
                    [],
                    [
                        16,
                        2
                    ]
                ],
                "num_parameters": [
                    23440896,
                    393216,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    1536,
                    2
                ]
            },
            {
                "name": "module",
                "id": 140000506367280,
                "class_name": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)",
                "parameters": [
                    [
                        "distilbert.embeddings.word_embeddings.weight",
                        [
                            30522,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.position_embeddings.weight",
                        [
                            512,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "pre_classifier.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "pre_classifier.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "classifier.weight",
                        [
                            2,
                            768
                        ]
                    ],
                    [
                        "classifier.bias",
                        [
                            2
                        ]
                    ]
                ],
                "output_shape": [
                    [],
                    [
                        16,
                        2
                    ]
                ],
                "num_parameters": [
                    23440896,
                    393216,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    1536,
                    2
                ]
            },
            {
                "name": "module",
                "id": 140000506367672,
                "class_name": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (1): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (2): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (3): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (4): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n        (5): TransformerBlock(\n          (dropout): Dropout(p=0.1, inplace=False)\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)",
                "parameters": [
                    [
                        "distilbert.embeddings.word_embeddings.weight",
                        [
                            30522,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.position_embeddings.weight",
                        [
                            512,
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.embeddings.LayerNorm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.0.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.1.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.2.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.3.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.4.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.q_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.k_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.v_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.attention.out_lin.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.sa_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.weight",
                        [
                            3072,
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin1.bias",
                        [
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.weight",
                        [
                            768,
                            3072
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.ffn.lin2.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.weight",
                        [
                            768
                        ]
                    ],
                    [
                        "distilbert.transformer.layer.5.output_layer_norm.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "pre_classifier.weight",
                        [
                            768,
                            768
                        ]
                    ],
                    [
                        "pre_classifier.bias",
                        [
                            768
                        ]
                    ],
                    [
                        "classifier.weight",
                        [
                            2,
                            768
                        ]
                    ],
                    [
                        "classifier.bias",
                        [
                            2
                        ]
                    ]
                ],
                "output_shape": [
                    [],
                    [
                        16,
                        2
                    ]
                ],
                "num_parameters": [
                    23440896,
                    393216,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    589824,
                    768,
                    768,
                    768,
                    2359296,
                    3072,
                    2359296,
                    768,
                    768,
                    768,
                    589824,
                    768,
                    1536,
                    2
                ]
            }
        ],
        "edges": []
    }
}
